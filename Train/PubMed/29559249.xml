<?xml version='1.0' encoding='utf-8'?>
<document id="29559249"><sentence text="Position-aware deep multi-task learning for drug-drug interaction extraction." /><sentence text="A drug-drug interaction (DDI) is a situation in which a drug affects the activity of another drug synergistically or antagonistically when being administered together" /><sentence text=" The information of DDIs is crucial for healthcare professionals to prevent adverse drug events" /><sentence text=" Although some known DDIs can be found in purposely-built databases such as DrugBank, most information is still buried in scientific publications" /><sentence text=" Therefore, automatically extracting DDIs from biomedical texts is sorely needed" /><sentence text="" /><sentence text="In this paper, we propose a novel position-aware deep multi-task learning approach for extracting DDIs from biomedical texts" /><sentence text=" In particular, sentences are represented as a sequence of word embeddings and position embeddings" /><sentence text=" An attention-based bidirectional long short-term memory (BiLSTM) network is used to encode each sentence" /><sentence text=" The relative position information of words with the target drugs in text is combined with the hidden states of BiLSTM to generate the position-aware attention weights" /><sentence text=" Moreover, the tasks of predicting whether or not two drugs interact with each other and further distinguishing the types of interactions are learned jointly in multi-task learning framework" /><sentence text="" /><sentence text="The proposed approach has been evaluated on the DDIExtraction challenge 2013 corpus and the results show that with the position-aware attention only, our proposed approach outperforms the state-of-the-art method by 0" /><sentence text="99% for binary DDI classification, and with both position-aware attention and multi-task learning, our approach achieves a micro F-score of 72" /><sentence text="99% on interaction type identification, outperforming the state-of-the-art approach by 1" /><sentence text="51%, which demonstrates the effectiveness of the proposed approach" /><sentence text="" /></document>